{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_tag = \"Instacart Market Basket\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSLabs functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"scripts/dslabs_functions.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_functions lodaded\n"
     ]
    }
   ],
   "source": [
    "%run \"scripts/data_functions.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sampling and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3421083 entries, 0 to 3421082\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   order_id                int64  \n",
      " 1   user_id                 int64  \n",
      " 2   order_number            int64  \n",
      " 3   order_dow               int64  \n",
      " 4   order_hour_of_day       int64  \n",
      " 5   days_since_prior_order  float64\n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 156.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test_data=True\n",
    "test_data=False\n",
    "\n",
    "\n",
    "# Define the sampling function\n",
    "def sample_user_orders(data, fraction=0.1):\n",
    "    # Get unique user_ids and order_ids\n",
    "    unique_user_orders = data[['user_id', 'order_id']].drop_duplicates()\n",
    "    sampled_user_orders = unique_user_orders.sample(frac=fraction)\n",
    "    \n",
    "    # Filter the dataset to include only the sampled users and orders\n",
    "    sampled_data = data[data[['user_id', 'order_id']].apply(tuple, axis=1).isin(sampled_user_orders.apply(tuple, axis=1))]\n",
    "    return sampled_data\n",
    "\n",
    "\n",
    "# Load the data\n",
    "orders = pd.read_csv('data/input/orders.csv')\n",
    "\n",
    "\n",
    "if test_data==True:\n",
    "\n",
    "\n",
    "\n",
    "    # Apply the sampling to each group 1%\n",
    "    sample=0.05\n",
    "    order_data = sample_user_orders(orders, fraction=sample)\n",
    "    \n",
    "\n",
    "else:\n",
    "    \n",
    "    order_data = orders\n",
    "    order_data = sample_user_orders(orders, fraction=sample)\n",
    "    \n",
    "    \n",
    "# drop eval_set as its not necessary\n",
    "order_data=order_data.drop(['eval_set'], axis=1)\n",
    "\n",
    "print(order_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge orders with prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior=pd.read_csv('data/input/order_products__prior.csv')\n",
    "\n",
    "\n",
    "# merge the two dataframes on order id\n",
    "data = pd.merge(prior,order_data , on='order_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reordered\n",
      "1    0.589697\n",
      "0    0.410303\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target = \"reordered\"\n",
    "\n",
    "values = data[target].value_counts(normalize=True) \n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32434489, 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.243449e+07</td>\n",
       "      <td>3.243449e+07</td>\n",
       "      <td>3.243449e+07</td>\n",
       "      <td>3.243449e+07</td>\n",
       "      <td>3.243449e+07</td>\n",
       "      <td>3.243449e+07</td>\n",
       "      <td>3.243449e+07</td>\n",
       "      <td>3.243449e+07</td>\n",
       "      <td>3.035642e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.710749e+06</td>\n",
       "      <td>2.557634e+04</td>\n",
       "      <td>8.351076e+00</td>\n",
       "      <td>5.896975e-01</td>\n",
       "      <td>1.029372e+05</td>\n",
       "      <td>1.714205e+01</td>\n",
       "      <td>2.738818e+00</td>\n",
       "      <td>1.342498e+01</td>\n",
       "      <td>1.110407e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.873007e+05</td>\n",
       "      <td>1.409669e+04</td>\n",
       "      <td>7.126671e+00</td>\n",
       "      <td>4.918886e-01</td>\n",
       "      <td>5.946648e+04</td>\n",
       "      <td>1.753504e+01</td>\n",
       "      <td>2.090049e+00</td>\n",
       "      <td>4.246365e+00</td>\n",
       "      <td>8.778914e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.559430e+05</td>\n",
       "      <td>1.353000e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.142100e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.711048e+06</td>\n",
       "      <td>2.525600e+04</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026110e+05</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.565514e+06</td>\n",
       "      <td>3.793500e+04</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.543910e+05</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>4.968800e+04</td>\n",
       "      <td>1.450000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.062090e+05</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id    product_id  add_to_cart_order     reordered  \\\n",
       "count  3.243449e+07  3.243449e+07       3.243449e+07  3.243449e+07   \n",
       "mean   1.710749e+06  2.557634e+04       8.351076e+00  5.896975e-01   \n",
       "std    9.873007e+05  1.409669e+04       7.126671e+00  4.918886e-01   \n",
       "min    2.000000e+00  1.000000e+00       1.000000e+00  0.000000e+00   \n",
       "25%    8.559430e+05  1.353000e+04       3.000000e+00  0.000000e+00   \n",
       "50%    1.711048e+06  2.525600e+04       6.000000e+00  1.000000e+00   \n",
       "75%    2.565514e+06  3.793500e+04       1.100000e+01  1.000000e+00   \n",
       "max    3.421083e+06  4.968800e+04       1.450000e+02  1.000000e+00   \n",
       "\n",
       "            user_id  order_number     order_dow  order_hour_of_day  \\\n",
       "count  3.243449e+07  3.243449e+07  3.243449e+07       3.243449e+07   \n",
       "mean   1.029372e+05  1.714205e+01  2.738818e+00       1.342498e+01   \n",
       "std    5.946648e+04  1.753504e+01  2.090049e+00       4.246365e+00   \n",
       "min    1.000000e+00  1.000000e+00  0.000000e+00       0.000000e+00   \n",
       "25%    5.142100e+04  5.000000e+00  1.000000e+00       1.000000e+01   \n",
       "50%    1.026110e+05  1.100000e+01  3.000000e+00       1.300000e+01   \n",
       "75%    1.543910e+05  2.400000e+01  5.000000e+00       1.600000e+01   \n",
       "max    2.062090e+05  9.900000e+01  6.000000e+00       2.300000e+01   \n",
       "\n",
       "       days_since_prior_order  \n",
       "count            3.035642e+07  \n",
       "mean             1.110407e+01  \n",
       "std              8.778914e+00  \n",
       "min              0.000000e+00  \n",
       "25%              5.000000e+00  \n",
       "50%              8.000000e+00  \n",
       "75%              1.500000e+01  \n",
       "max              3.000000e+01  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary5 = data.describe(include=\"all\")\n",
    "\n",
    "summary5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional date columns creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the time of day\n",
    "def categorize_time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 22:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "data['order_time_of_day'] = data['order_hour_of_day'].apply(categorize_time_of_day)\n",
    "\n",
    "data['is_weekend'] = data['order_dow'].apply(lambda x: 1 if x >= 5 else 0)  # 1 for weekend, 0 for weekday\n",
    "\n",
    "data['is_peak_time_of_day']=data['order_time_of_day'].apply(lambda x: 1 if x in ['Morning','Afternoon'] else 0)\n",
    "\n",
    "data['weeks_since_prior_order'] = data['days_since_prior_order'].apply(lambda x: round(x / 7, 0) if pd.notnull(x) else np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode date time to cyclic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi, sin, cos\n",
    "\n",
    "# Function to apply sin and cos on an already-mapped cyclic feature\n",
    "def apply_sin_cos_for_mapped_column(data, column):\n",
    "    data[column + '_sin'] = np.sin(data[column])  # apply sine\n",
    "    data[column + '_cos'] = np.cos(data[column])  # apply cosine\n",
    "    return data\n",
    "\n",
    "# Function to encode cyclic variables using sine and cosine\n",
    "def cyclic_encode(value, x_max):\n",
    "    # sine and cosine components to capture cyclic pattern\n",
    "    value_sin = np.sin(2 * np.pi * value / x_max)\n",
    "    value_cos = np.cos(2 * np.pi * value / x_max)\n",
    "    return value_sin, value_cos\n",
    "\n",
    "\n",
    "day_of_week_encoding_mapping={\n",
    "    'Night':0,   \n",
    "    'Morning':pi/2,\n",
    "    'Afternoon':pi,\n",
    "    'Evening':-pi/2,   \n",
    "}\n",
    "\n",
    "data['order_time_of_day_enc'] = encode_column_with_mapping(data, 'order_time_of_day', day_of_week_encoding_mapping)\n",
    "\n",
    "\n",
    "# Encoding for local_hour (0-23)\n",
    "data['order_hour_of_day_sin'], data['order_hour_of_day_cos'] = zip(*data['order_hour_of_day'].apply(lambda x: cyclic_encode(x, 23)))\n",
    "\n",
    "# Encoding for day_of_week (0-6)\n",
    "data['order_dow_sin'], data['order_dow_cos'] = zip(*data['order_dow'].apply(lambda x: cyclic_encode(x, 6)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user order dataframe for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by order_id and aggregate features\n",
    "order_agg = data.groupby('order_id').agg({\n",
    "    'add_to_cart_order': 'max',\n",
    "    'reordered': 'mean',\n",
    "}).rename(columns={'add_to_cart_order': 'num_products', 'reordered': 'reorder_rate'})\n",
    "\n",
    "\n",
    "data=data.merge(order_agg, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>total_orders</th>\n",
       "      <th>mean_products</th>\n",
       "      <th>max_products</th>\n",
       "      <th>std_num_products</th>\n",
       "      <th>mean_lag_between_orders</th>\n",
       "      <th>std_lag_between_orders</th>\n",
       "      <th>mean_reorder_rate</th>\n",
       "      <th>mean_weekend_order_rate</th>\n",
       "      <th>mean_order_dow</th>\n",
       "      <th>top_order_dow</th>\n",
       "      <th>order_dow_variety</th>\n",
       "      <th>top_order_hour</th>\n",
       "      <th>order_hour_variety</th>\n",
       "      <th>std_order_hour</th>\n",
       "      <th>mean_peak_time_of_day_rate</th>\n",
       "      <th>top_order_time_of_day_enc</th>\n",
       "      <th>order_time_of_day_enc_variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.254237</td>\n",
       "      <td>9</td>\n",
       "      <td>1.582155</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>9.304463</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.644068</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3.500355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>16.107692</td>\n",
       "      <td>26</td>\n",
       "      <td>5.469097</td>\n",
       "      <td>15.967033</td>\n",
       "      <td>9.119769</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>2.005128</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.649854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>7.886364</td>\n",
       "      <td>11</td>\n",
       "      <td>2.042265</td>\n",
       "      <td>11.487179</td>\n",
       "      <td>4.869048</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1.454599</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>7</td>\n",
       "      <td>2.120550</td>\n",
       "      <td>15.357143</td>\n",
       "      <td>8.580901</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.722222</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1.745208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10.027027</td>\n",
       "      <td>12</td>\n",
       "      <td>2.315245</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>4.263801</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2.588958</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  total_orders  mean_products  max_products  std_num_products  \\\n",
       "0        1            10       6.254237             9          1.582155   \n",
       "1        2            14      16.107692            26          5.469097   \n",
       "2        3            12       7.886364            11          2.042265   \n",
       "3        4             5       4.555556             7          2.120550   \n",
       "4        5             4      10.027027            12          2.315245   \n",
       "\n",
       "   mean_lag_between_orders  std_lag_between_orders  mean_reorder_rate  \\\n",
       "0                20.259259                9.304463           0.694915   \n",
       "1                15.967033                9.119769           0.476923   \n",
       "2                11.487179                4.869048           0.625000   \n",
       "3                15.357143                8.580901           0.055556   \n",
       "4                14.500000                4.263801           0.378378   \n",
       "\n",
       "   mean_weekend_order_rate  mean_order_dow  top_order_dow  order_dow_variety  \\\n",
       "0                 0.000000        2.644068              4                  4   \n",
       "1                 0.030769        2.005128              2                  5   \n",
       "2                 0.000000        1.011364              0                  4   \n",
       "3                 0.500000        4.722222              4                  3   \n",
       "4                 0.000000        1.621622              3                  3   \n",
       "\n",
       "   top_order_hour  order_hour_variety  std_order_hour  \\\n",
       "0               7                   7        3.500355   \n",
       "1               9                   5        1.649854   \n",
       "2              16                   6        1.454599   \n",
       "3              15                   3        1.745208   \n",
       "4              18                   3        2.588958   \n",
       "\n",
       "   mean_peak_time_of_day_rate  top_order_time_of_day_enc  \\\n",
       "0                    1.000000                   1.570796   \n",
       "1                    1.000000                   1.570796   \n",
       "2                    0.568182                   3.141593   \n",
       "3                    1.000000                   3.141593   \n",
       "4                    0.540541                   3.141593   \n",
       "\n",
       "   order_time_of_day_enc_variety  \n",
       "0                              2  \n",
       "1                              2  \n",
       "2                              2  \n",
       "3                              2  \n",
       "4                              2  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop product_id column and get unique values per order_id\n",
    "distinct_orders = data.drop(columns=['product_id']).drop_duplicates()\n",
    "\n",
    "# Group by user_id and aggregate features using named aggregations\n",
    "user_agg = distinct_orders.groupby('user_id').agg(\n",
    "    total_orders=('order_number', 'max'),  # Total number of orders\n",
    "    mean_products=('num_products', 'mean'),  # mean products purchased\n",
    "    max_products=('num_products', 'max'),  # max products ever purchased\n",
    "    std_num_products=('num_products', 'std'),  # std products purchased\n",
    "    mean_lag_between_orders=('days_since_prior_order', 'mean'),\n",
    "    std_lag_between_orders=('days_since_prior_order', 'std'),\n",
    "    mean_reorder_rate=('reorder_rate', 'mean'),\n",
    "    mean_weekend_order_rate=('is_weekend', 'mean'),\n",
    "    mean_order_dow=('order_dow', 'mean'),\n",
    "    top_order_dow=('order_dow', lambda x: x.mode()[0]),\n",
    "    order_dow_variety=('order_dow', lambda x: x.nunique()),\n",
    "    top_order_hour=('order_hour_of_day', lambda x: x.mode()[0]),\n",
    "    order_hour_variety=('order_hour_of_day', lambda x: x.nunique()),\n",
    "    std_order_hour=('order_hour_of_day', 'std'),\n",
    "    mean_peak_time_of_day_rate=('is_peak_time_of_day', 'mean'),\n",
    "    top_order_time_of_day_enc=('order_time_of_day_enc', lambda x: x.mode()[0]),\n",
    "    order_time_of_day_enc_variety=('order_time_of_day_enc', lambda x: x.nunique()),\n",
    "\n",
    "\n",
    ").reset_index()\n",
    "\n",
    "# Handle NaN values (if needed)\n",
    "user_agg = user_agg.fillna(0)  # or user_agg.dropna()\n",
    "\n",
    "user_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enrich main order product dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.14 GiB for an array with shape (13, 32434489) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m enriched_data \u001b[38;5;241m=\u001b[39m enrich_instacart_df(data)\n",
      "File \u001b[1;32m~\\CODING\\ist_dash_2024_rec\\non_supervised_analysis\\notebooks\\dataset_3\\scripts\\data_functions.py:1300\u001b[0m, in \u001b[0;36menrich_instacart_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m   1296\u001b[0m products \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/input/products.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1297\u001b[0m departments \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/input/departments.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1299\u001b[0m enriched_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(products, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m-> 1300\u001b[0m                 \u001b[38;5;241m.\u001b[39mmerge(aisles, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maisle_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[0;32m   1301\u001b[0m                 \u001b[38;5;241m.\u001b[39mmerge(departments, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepartment_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enriched_df\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10833\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10834\u001b[0m         right,\n\u001b[0;32m  10835\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m  10836\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m  10837\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m  10838\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m  10839\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m  10840\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m  10841\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m  10842\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m  10843\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m  10844\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m  10845\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10846\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:879\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    877\u001b[0m left\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m llabels\n\u001b[0;32m    878\u001b[0m right\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m rlabels\n\u001b[1;32m--> 879\u001b[0m result \u001b[38;5;241m=\u001b[39m concat([left, right], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     mgrs \u001b[38;5;241m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mgrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs_indexers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mgrs_indexers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnblocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[0;32m    220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    221\u001b[0m             axes[i],\n\u001b[0;32m    222\u001b[0m             indexers[i],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m             use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[1;32m--> 230\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    232\u001b[0m     new_mgrs\u001b[38;5;241m.\u001b[39mappend(mgr)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:604\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    601\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 604\u001b[0m     res\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2270\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2271\u001b[0m     )\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ist\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2301\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2298\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2300\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2301\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2302\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2304\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.14 GiB for an array with shape (13, 32434489) and data type int64"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "enriched_data = enrich_instacart_df(data)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data==False:\n",
    "    \n",
    "    data.to_csv('data/instacart_pre_proc.csv',index=False)\n",
    "\n",
    "    user_agg.to_csv('data/instacart_user_pre_proc.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sampling to each group 20%\n",
    "sample=0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data==False:\n",
    "    \n",
    "    sample_data = sample_user_orders(data, fraction=sample)\n",
    "\n",
    "    sample_data.to_csv('data/instacart_pre_proc_sample.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data==False:\n",
    "    \n",
    "    users_df_sample=user_agg.sample(frac=sample)\n",
    "    \n",
    "    users_df_sample.to_csv('data/instacart_user_pre_proc_sample.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
