{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling and Analysis Questions\n",
    "\n",
    "\n",
    "Clustering\n",
    "https://web.ist.utl.pt/rmch/dash/guides/Clustering%20in%20Python.html\n",
    "\n",
    "\n",
    "- what are the top aisle purchase clusters?\n",
    "- what are the most common timeframe order time clusters (order_dow, order_hour_of_day,days_since_prior_order and weeks_since_prior_order) ?\n",
    "\n",
    "PCA Resources\n",
    "- https://www.kaggle.com/code/asindico/customer-segments-with-pca\n",
    "- https://www.datacamp.com/tutorial/principal-component-analysis-in-python\n",
    "- https://www.youtube.com/watch?v=8klqIM9UvAc\n",
    "- https://www.youtube.com/watch?v=FD4DeN81ODY\n",
    "- https://www.youtube.com/watch?v=HMOI_lkzW08\n",
    "\n",
    "\n",
    "# NOTAS PROF\n",
    "- DETETAR E EXCLUIR OUTLIERS DOS CLUSTERS PEQUENOS \n",
    "- ADICIONAR DENDROGRAMA DOS CLUSTERS\n",
    "- EXPERIMENTAR DBSCAN\n",
    "- ADICIONAR E VALIDAR CENTROIDES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "filepath=r'/Users/cozmaeug/Private/IST PG - DS/DaSH ENG/ist_dash_2024_rec/non_supervised_analysis/notebooks/dataset_2/df_bakery_encoded.csv'\n",
    "\n",
    "file_tag = \"Bakery Pattern Mining\"\n",
    "\n",
    "data = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"scripts/dslabs_functions.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_functions lodaded\n"
     ]
    }
   ],
   "source": [
    "%run \"scripts/data_functions.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy=data.copy()\n",
    "data_copy = data_copy.dropna(axis=0, how=\"any\") #axis=0 tells dropna to remove rows that have at least one NaN value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and normalizing data\n",
    "K-Means is sensitive to scale. If your dataset has different units (e.g., money, time, percentages), consider standardizing it before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_copy)  # Apply scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [prof] Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan distance\n",
    "- It sums absolute differences across features.\n",
    "- Each feature has the same weight (1), meaning all are treated equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def mydistance(x1, x2):\n",
    "    res = 0\n",
    "    fix_weight = 1\n",
    "    for j in range(len(x1)):\n",
    "        res += fix_weight*abs(x1[j]-x2[j])\n",
    "    return res\n",
    "\n",
    "def affinity(X):\n",
    "    return pairwise_distances(X, metric=mydistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier_algo = cluster.AgglomerativeClustering(n_clusters=3, metric='euclidean', linkage='average')\n",
    "hier_model = hier_algo.fit(data_copy)\n",
    "hier_model.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [prof] Customized distance\n",
    "Weighted Manhattan Distance: Still based on Manhattan Distance, but now some features contribute more than others:\n",
    "Instead of treating all features equally, it assigns different importance:\n",
    "\n",
    "- Feature 1 → weight = 1\n",
    "- Feature 2 → weight = 2\n",
    "- Feature 3 → weight = 3\n",
    "- Feature 4 → weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def mydistance(x1, x2):\n",
    "    res = 0.0001 #Avoids zero distances when points are identical; Helps prevent division-by-zero issues in clustering.\n",
    "    for j, weight in enumerate([1,2,3,1]):\n",
    "        res += weight*abs(x1[j]-x2[j])\n",
    "    return res\n",
    "\n",
    "def sim_affinity(X):\n",
    "    return pairwise_distances(X, metric=mydistance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier_algo = cluster.AgglomerativeClustering(n_clusters=5, affinity=affinity, linkage='complete')\n",
    "hier_model = hier_algo.fit(data_copy)\n",
    "hier_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette: 0.74831119558551\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Silhouette:\",metrics.silhouette_score(data_copy, hier_model.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [prof] Evaluating the clustering solution using internal indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette: 0.7006085605777561\n",
      "Silhouette per instance:\n",
      " [0.48101275 0.84371167 0.39126744 0.82414381 0.84097135] ...\n",
      "Sum of squared distances: 62018680949.56879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = kmeans_model.labels_\n",
    "print(\"Silhouette:\",metrics.silhouette_score(data_copy, y_pred))\n",
    "print(\"Silhouette per instance:\\n\",metrics.silhouette_samples(data_copy, y_pred)[:5],\"...\")\n",
    "print(\"Sum of squared distances:\",kmeans_model.inertia_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['cluster']=hier_model.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x=\"cluster\", y='total', data=data_copy)      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K MEANS clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow Method Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# Define the range of clusters to evaluate\n",
    "range_n_clusters = list(range(1, 11))\n",
    "\n",
    "# Initialize an empty list to store the sum of squared distances\n",
    "sse = []\n",
    "\n",
    "# Loop over the range of clusters\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(data_copy)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# Determine the elbow point using KneeLocator\n",
    "kneedle = KneeLocator(range_n_clusters, sse, curve='convex', direction='decreasing')\n",
    "elbow_point = kneedle.elbow\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_n_clusters, sse, marker='o')\n",
    "plt.title(f'{file_tag} | Elbow Method for Optimal KMeans Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Sum of Squared Errors')\n",
    "\n",
    "# Add a vertical line at the elbow point\n",
    "plt.axvline(x=elbow_point, color='r', linestyle='--')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the Optimal K After Elbow Method\n",
    "print(f\"Optimal number of clusters (Elbow Method): {elbow_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27019827, -0.05911589, -0.00563971, -0.05246349, -0.67139829,\n",
       "        -0.37110241,  0.00174243],\n",
       "       [ 0.46008072,  0.10065971,  0.00960303,  0.08933232,  1.14322497,\n",
       "         0.63189549, -0.00296693]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clustering\n",
    "from sklearn import cluster, mixture\n",
    "\n",
    "# Starting from Scikit-learn 1.4, n_init='auto' is recommended for K-Means - it prevents future compatibility issues.\n",
    "\n",
    "bakery_kmeans = KMeans(n_clusters=5, random_state=42, n_init='auto')\n",
    "bakery_y_pred_kmeans = bakery_kmeans.fit_predict(data_scaled)\n",
    "\n",
    "bakery_kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          total  angbutter  plain bread       jam  americano  croissant  \\\n",
      "0  1.825116e+04   1.138031     0.391892  0.095077   0.188707   0.361486   \n",
      "1  1.293000e+06   6.000000     5.000000  0.000000   0.000000   5.000000   \n",
      "2  3.495130e+04   2.492795     0.608069  0.149856   0.351585   0.850144   \n",
      "\n",
      "   caffe latte  tiramisu croissant  cacao deep  pain au chocolat  ...  \\\n",
      "0     0.082529            0.335907    0.143340          0.258687  ...   \n",
      "1     0.000000            0.000000    0.000000          5.000000  ...   \n",
      "2     0.123919            0.717579    0.193084          0.533141  ...   \n",
      "\n",
      "   hour_cos   min_sin   min_cos  day_of_month_sin  day_of_month_cos  \\\n",
      "0 -0.861576  0.075113  0.043259         -0.012735          0.003295   \n",
      "1 -0.991000 -0.638000 -0.770000         -0.849000          0.529000   \n",
      "2 -0.875398  0.111781  0.058625         -0.042285          0.021715   \n",
      "\n",
      "   day_of_week_nr_sin  day_of_week_nr_cos  week_of_month_sin  \\\n",
      "0           -0.157986            0.168436           0.088803   \n",
      "1           -0.866000           -0.500000           0.000000   \n",
      "2           -0.109810            0.095101           0.083573   \n",
      "\n",
      "   week_of_month_cos   cluster  \n",
      "0           0.022201  1.000000  \n",
      "1           1.000000  3.000000  \n",
      "2           0.005764  1.285303  \n",
      "\n",
      "[3 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "centroids = bakery_kmeans.cluster_centers_\n",
    "\n",
    "feature_names = data_copy.columns.tolist()\n",
    "\n",
    "centroid_df = pd.DataFrame(data=centroids, columns=feature_names)\n",
    "print(\"Cluster Centroids:\")\n",
    "print(centroid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the clusters per instance\n",
    "cluster_labels = bakery_kmeans.labels_\n",
    "print(\"Cluster Labels:\")\n",
    "print(cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sillhouete study for kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the range of clusters to evaluate\n",
    "range_n_clusters = list(range(2, 11))\n",
    "\n",
    "# Initialize an empty list to store the silhouette scores\n",
    "silhouette_scores = []\n",
    "\n",
    "# Loop over the range of clusters\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(data_copy)\n",
    "    silhouette_avg = silhouette_score(data_copy, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
    "plt.title(f'{file_tag} | Silhouette Scores for KMeans Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Best K After Silhouette Analysis\n",
    "\n",
    "best_k = range_n_clusters[silhouette_scores.index(max(silhouette_scores))]\n",
    "print(f\"Optimal number of clusters (Silhouette Score): {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [prof] Plotting clustering solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cluster parameters\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05, hspace=.01)\n",
    "color_array = ['#377eb8','#ff7f00','#4daf4a','#f781bf','#a65628','#984ea3','#999999','#e41a1c','#dede00']\n",
    "plot_num = 1\n",
    "for k in range(len(datasets)):\n",
    "    predictions = all_predictions[k]\n",
    "    efficiency = all_efficiency[k]\n",
    "    X, y = datasets[k][0]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    for name in predictions:\n",
    "        y_pred = predictions[name]\n",
    "        plt.subplot(len(datasets), len(algorithms), plot_num)\n",
    "        if k == 0: plt.title(name, size=10)\n",
    "        colors = np.array(list(islice(cycle(color_array),int(max(y_pred) + 1))))\n",
    "        colors = np.append(colors, [\"#000000\"]) #black color for outliers (if any)\n",
    "        \n",
    "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "        plt.xlim(-2.5, 2.5)\n",
    "        plt.ylim(-2.5, 2.5)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.text(.99, .01, ('%.2fs' % efficiency[name]).lstrip('0'),\n",
    "                 transform=plt.gca().transAxes,size=15,horizontalalignment='right')\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others: spectral, agglomerative, dbscan, model-based\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cluster Heatmap (For Feature Importance)\n",
    "Another way to analyze clustering is by visualizing the centroid values for each feature.\n",
    "\n",
    "Heatmap of Cluster Centroids: Helps interpret which features are important for each cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe of centroids\n",
    "centroids = pd.DataFrame(bakery_kmeans.cluster_centers_, columns=data_copy.columns)\n",
    "\n",
    "# Plot a heatmap of feature values for each cluster\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(centroids.T, cmap=\"coolwarm\", annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"K-Means Cluster Centroids\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.599017</td>\n",
       "      <td>-0.185011</td>\n",
       "      <td>-0.908678</td>\n",
       "      <td>1.286388</td>\n",
       "      <td>0.514383</td>\n",
       "      <td>0.836274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.738243</td>\n",
       "      <td>0.267580</td>\n",
       "      <td>-1.241109</td>\n",
       "      <td>-1.036334</td>\n",
       "      <td>-0.167371</td>\n",
       "      <td>-1.384709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.547021</td>\n",
       "      <td>1.050453</td>\n",
       "      <td>0.877761</td>\n",
       "      <td>-0.585861</td>\n",
       "      <td>0.651541</td>\n",
       "      <td>0.365785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.657266</td>\n",
       "      <td>0.439276</td>\n",
       "      <td>-0.525110</td>\n",
       "      <td>-0.277721</td>\n",
       "      <td>-1.629132</td>\n",
       "      <td>0.361978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.943730</td>\n",
       "      <td>0.943847</td>\n",
       "      <td>1.177913</td>\n",
       "      <td>0.454520</td>\n",
       "      <td>1.209342</td>\n",
       "      <td>-1.794241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6\n",
       "0  2.599017 -0.185011 -0.908678  1.286388  0.514383  0.836274\n",
       "1 -1.738243  0.267580 -1.241109 -1.036334 -0.167371 -1.384709\n",
       "2 -0.547021  1.050453  0.877761 -0.585861  0.651541  0.365785\n",
       "3 -0.657266  0.439276 -0.525110 -0.277721 -1.629132  0.361978\n",
       "4 -0.943730  0.943847  1.177913  0.454520  1.209342 -1.794241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "pca = PCA(n_components=6)\n",
    "bakery_pca = pca.fit_transform(data_copy)\n",
    "\n",
    "pca_bakery_df = pd.DataFrame(bakery_pca, columns=[f'PC{i+1}' for i in range(bakery_pca.shape[1])])\n",
    "pca_bakery_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA  explained variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.2266113  0.16750973 0.15027046 0.14209286 0.13990889 0.10285501]\n"
     ]
    }
   ],
   "source": [
    "# Fit the PCA model\n",
    "pca.fit(data_copy)\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance_reorder = pca.explained_variance_ratio_\n",
    "print(f'Explained variance ratio: {explained_variance_reorder}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D PCA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# KMeans Clustering\n",
    "plt.subplot(121)\n",
    "plt.scatter(pca_bakery_df['PC1'], pca_bakery_df['PC2'], c=bakery_y_pred_kmeans, cmap='viridis', alpha=0.5)\n",
    "kmeans_centroids = pca.transform(bakery_kmeans.cluster_centers_)\n",
    "plt.scatter(kmeans_centroids[:, 0], kmeans_centroids[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('KMeans Clustering')\n",
    "plt.legend()\n",
    "\n",
    "# Agglomerative Clustering\n",
    "plt.subplot(122)\n",
    "plt.scatter(pca_bakery_df['PC1'], pca_bakery_df['PC2'], c=bakery_y_pred_kmeans, cmap='viridis', alpha=0.5)\n",
    "# Agglomerative clustering does not have centroids, so we skip this part\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Agglomerative Clustering')\n",
    "\n",
    "plt.suptitle(f\"{file_tag} | PCA Cluster Visualization\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D PCA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# KMeans Clustering\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.scatter(pca_bakery_df['PC1'], pca_bakery_df['PC2'], pca_bakery_df['PC3'], c=bakery_y_pred_kmeans, cmap='viridis', alpha=0.5)\n",
    "kmeans_centroids_3d = pca.transform(bakery_kmeans.cluster_centers_)\n",
    "ax.scatter(kmeans_centroids_3d[:, 0], kmeans_centroids_3d[:, 1], kmeans_centroids_3d[:, 2], c='red', marker='X', s=200, label='Centroids')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('KMeans Clustering')\n",
    "ax.legend()\n",
    "\n",
    "# Agglomerative Clustering\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.scatter(pca_bakery_df['PC1'], pca_bakery_df['PC2'], pca_bakery_df['PC3'], c=bakery_y_pred_kmeans, cmap='viridis', alpha=0.5)\n",
    "# Agglomerative clustering does not have centroids, so we skip this part\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('Agglomerative Clustering')\n",
    "\n",
    "fig.suptitle(f\"{file_tag} | PCA Cluster Visualization\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
